<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LLM SuperCLI · Multi-Provider LLM Command Line Interface</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <meta name="description" content="A powerful multi-provider LLM command line interface with Gemini, Qwen, Groq, Ollama, OpenRouter, Together AI, and HuggingFace support." />
</head>
<body class="min-h-screen bg-slate-950 text-slate-50">
  <div class="relative isolate overflow-hidden">
    <div class="pointer-events-none absolute inset-x-0 top-0 -z-10 transform-gpu overflow-hidden blur-3xl">
      <div class="relative left-1/2 aspect-[1108/632] w-[72rem] -translate-x-1/2 bg-gradient-to-tr from-indigo-500 via-sky-400 to-emerald-400 opacity-30"></div>
    </div>

    <header class="border-b border-slate-800 bg-slate-950/80 backdrop-blur">
      <nav class="mx-auto flex max-w-6xl items-center justify-between px-4 py-4 sm:px-6 lg:px-8" aria-label="Main navigation">
        <a href="#home" class="flex items-center gap-2">
          <span class="inline-flex h-8 w-8 items-center justify-center rounded-md bg-sky-500 text-sm font-semibold text-slate-950">CLI</span>
          <span class="text-lg font-semibold tracking-tight text-slate-50">LLM SuperCLI</span>
        </a>

        <div class="hidden items-center gap-8 text-sm font-medium text-slate-200 md:flex">
          <a href="#home" class="hover:text-sky-300">Home</a>
          <a href="#features" class="hover:text-sky-300">Features</a>
          <a href="#providers" class="hover:text-sky-300">Providers</a>
          <a href="#installation" class="hover:text-sky-300">Installation</a>
          <a href="#commands" class="hover:text-sky-300">Commands</a>
          <a href="https://github.com/llm-supercli/llm-supercli" target="_blank" rel="noreferrer" class="hover:text-sky-300">Repository</a>
        </div>

        <div class="flex items-center gap-3 md:gap-4">
          <a href="https://github.com/llm-supercli/llm-supercli" target="_blank" rel="noreferrer" class="hidden text-sm font-medium text-slate-200 hover:text-sky-300 sm:inline">
            GitHub
          </a>
        </div>
      </nav>
    </header>

    <main id="home" class="mx-auto max-w-6xl px-4 pb-16 pt-10 sm:px-6 lg:px-8 lg:pb-24 lg:pt-16">
      <!-- Hero -->
      <section class="grid gap-10 md:grid-cols-[minmax(0,3fr)_minmax(0,2fr)] md:items-center">
        <div>
          <h1 class="text-3xl font-bold tracking-tight text-slate-50 sm:text-4xl lg:text-5xl">
            LLM SuperCLI
          </h1>
          <p class="mt-4 max-w-xl text-base text-slate-200 sm:text-lg">
            A powerful multi-provider LLM command line interface with free tiers available.
          </p>
          <p class="mt-3 max-w-xl text-sm text-slate-400">
            Connect to Gemini, Qwen, Groq, Ollama, OpenRouter, Together AI, and HuggingFace. Rich terminal UI with streaming, autocomplete, and session management.
          </p>

          <div class="mt-8 flex flex-wrap gap-3">
            <a
              href="https://www.npmjs.com/package/llm-supercli"
              target="_blank"
              rel="noreferrer"
              class="inline-flex items-center justify-center rounded-md bg-sky-500 px-5 py-2.5 text-sm font-semibold text-slate-950 shadow-sm transition hover:bg-sky-400 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-sky-400 focus-visible:ring-offset-2 focus-visible:ring-offset-slate-950"
            >
              npm install -g llm-supercli
            </a>
            <a
              href="https://github.com/llm-supercli/llm-supercli"
              target="_blank"
              rel="noreferrer"
              class="inline-flex items-center justify-center rounded-md border border-slate-700 px-5 py-2.5 text-sm font-semibold text-slate-100 transition hover:border-sky-400 hover:text-sky-300 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-sky-400 focus-visible:ring-offset-2 focus-visible:ring-offset-slate-950"
            >
              View on GitHub
            </a>
          </div>

          <dl class="mt-8 grid max-w-lg grid-cols-3 gap-4 text-xs text-slate-400 sm:text-sm">
            <div>
              <dt class="font-semibold text-slate-200">Version</dt>
              <dd class="mt-1">1.0.18</dd>
            </div>
            <div>
              <dt class="font-semibold text-slate-200">Python</dt>
              <dd class="mt-1">3.10+</dd>
            </div>
            <div>
              <dt class="font-semibold text-slate-200">Free Tiers</dt>
              <dd class="mt-1">Gemini, Qwen, Ollama</dd>
            </div>
          </dl>
        </div>

        <div class="rounded-xl border border-slate-800 bg-slate-900/60 p-4 text-xs text-slate-100 shadow-lg shadow-sky-500/10 sm:p-5">
          <div class="flex items-center justify-between border-b border-slate-800 pb-2 text-[0.7rem] uppercase tracking-wide text-slate-400">
            <span>Terminal preview</span>
            <span class="flex gap-1">
              <span class="h-2 w-2 rounded-full bg-red-500"></span>
              <span class="h-2 w-2 rounded-full bg-amber-400"></span>
              <span class="h-2 w-2 rounded-full bg-emerald-500"></span>
            </span>
          </div>
          <pre class="mt-3 overflow-x-auto rounded-md bg-slate-950/60 p-3 font-mono text-[0.75rem] leading-relaxed text-slate-200">
$ npm install -g llm-supercli
$ llm

# Or include files in your prompt
$ Tell me about @src/main.py

# Execute shell commands
$ !git status

# Switch models on the fly
$ /model gemini-2.5-flash
          </pre>
        </div>
      </section>

      <!-- Features -->
      <section id="features" class="mt-16 scroll-mt-24">
        <h2 class="text-xl font-semibold text-slate-50 sm:text-2xl">Features</h2>
        <p class="mt-2 max-w-2xl text-sm text-slate-400">
          A rich terminal experience with multi-provider support and powerful built-in tools.
        </p>

        <div class="mt-6 grid gap-6 md:grid-cols-2 lg:grid-cols-4">
          <article class="flex flex-col gap-2 rounded-lg border border-slate-800 bg-slate-900/50 p-4">
            <h3 class="text-sm font-semibold text-slate-50">Multi-Provider Support</h3>
            <p class="text-sm text-slate-400">
              Groq, OpenRouter, Together AI, HuggingFace, Ollama, Gemini, and Qwen all in one CLI.
            </p>
          </article>
          <article class="flex flex-col gap-2 rounded-lg border border-slate-800 bg-slate-900/50 p-4">
            <h3 class="text-sm font-semibold text-slate-50">Streaming Responses</h3>
            <p class="text-sm text-slate-400">
              Real-time token streaming with reasoning display and syntax highlighting.
            </p>
          </article>
          <article class="flex flex-col gap-2 rounded-lg border border-slate-800 bg-slate-900/50 p-4">
            <h3 class="text-sm font-semibold text-slate-50">Built-in Tools</h3>
            <p class="text-sm text-slate-400">
              File operations, shell commands, directory navigation, and MCP server integration.
            </p>
          </article>
          <article class="flex flex-col gap-2 rounded-lg border border-slate-800 bg-slate-900/50 p-4">
            <h3 class="text-sm font-semibold text-slate-50">Session Management</h3>
            <p class="text-sm text-slate-400">
              Save, load, and manage conversation sessions. Compress context and rewind messages.
            </p>
          </article>
        </div>
      </section>

      <!-- Providers -->
      <section id="providers" class="mt-16 scroll-mt-24">
        <h2 class="text-xl font-semibold text-slate-50 sm:text-2xl">Supported Providers</h2>
        <p class="mt-2 max-w-2xl text-sm text-slate-400">
          Connect to multiple LLM providers with free tiers available for Gemini, Qwen, and Ollama.
        </p>

        <div class="mt-6 overflow-x-auto">
          <table class="w-full text-sm text-left">
            <thead class="text-xs uppercase bg-slate-900/50 text-slate-400">
              <tr>
                <th class="px-4 py-3 rounded-tl-lg">Provider</th>
                <th class="px-4 py-3">Models</th>
                <th class="px-4 py-3">Auth</th>
                <th class="px-4 py-3 rounded-tr-lg">Cost</th>
              </tr>
            </thead>
            <tbody class="divide-y divide-slate-800">
              <tr class="bg-slate-900/30">
                <td class="px-4 py-3 font-medium text-emerald-400">Qwen</td>
                <td class="px-4 py-3 text-slate-300">qwen3-coder-plus, qwen3-vl-plus</td>
                <td class="px-4 py-3 text-slate-400">OAuth</td>
                <td class="px-4 py-3 text-emerald-400">Free (2K req/day)</td>
              </tr>
              <tr class="bg-slate-900/30">
                <td class="px-4 py-3 font-medium text-emerald-400">Gemini</td>
                <td class="px-4 py-3 text-slate-300">gemini-2.5-pro, gemini-2.5-flash</td>
                <td class="px-4 py-3 text-slate-400">OAuth</td>
                <td class="px-4 py-3 text-emerald-400">Free</td>
              </tr>
              <tr class="bg-slate-900/30">
                <td class="px-4 py-3 font-medium text-emerald-400">Groq</td>
                <td class="px-4 py-3 text-slate-300">llama-3.3-70b, mixtral-8x7b, gemma2-9b</td>
                <td class="px-4 py-3 text-slate-400">API Key</td>
                <td class="px-4 py-3 text-emerald-400">Free tier</td>
              </tr>
              <tr class="bg-slate-900/30">
                <td class="px-4 py-3 font-medium text-emerald-400">Ollama</td>
                <td class="px-4 py-3 text-slate-300">llama3.2, mistral, codellama, phi3</td>
                <td class="px-4 py-3 text-slate-400">Local</td>
                <td class="px-4 py-3 text-emerald-400">Free</td>
              </tr>
              <tr class="bg-slate-900/30">
                <td class="px-4 py-3 font-medium text-slate-200">OpenRouter</td>
                <td class="px-4 py-3 text-slate-300">claude-3.5-sonnet, gpt-4o, gemini-pro</td>
                <td class="px-4 py-3 text-slate-400">API Key</td>
                <td class="px-4 py-3 text-slate-400">Paid</td>
              </tr>
              <tr class="bg-slate-900/30">
                <td class="px-4 py-3 font-medium text-slate-200">Together</td>
                <td class="px-4 py-3 text-slate-300">llama-3.1-405b, mixtral-8x22b</td>
                <td class="px-4 py-3 text-slate-400">API Key</td>
                <td class="px-4 py-3 text-slate-400">Paid</td>
              </tr>
              <tr class="bg-slate-900/30">
                <td class="px-4 py-3 font-medium text-slate-200 rounded-bl-lg">HuggingFace</td>
                <td class="px-4 py-3 text-slate-300">llama-3-70b, mixtral-8x7b</td>
                <td class="px-4 py-3 text-slate-400">API Key</td>
                <td class="px-4 py-3 text-slate-400 rounded-br-lg">Paid</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>

      <!-- Installation -->
      <section id="installation" class="mt-16 scroll-mt-24">
        <h2 class="text-xl font-semibold text-slate-50 sm:text-2xl">Installation</h2>
        <p class="mt-2 max-w-2xl text-sm text-slate-400">
          Install via npm (recommended) or pip and start chatting with LLMs in seconds.
        </p>

        <div class="mt-5 grid gap-6 lg:grid-cols-[minmax(0,3fr)_minmax(0,2fr)]">
          <div>
            <h3 class="text-sm font-semibold text-slate-200">Via npm (Recommended)</h3>
            <pre class="mt-2 overflow-x-auto rounded-md bg-slate-900/80 p-3 text-xs font-mono text-slate-100">npm install -g llm-supercli</pre>

            <h3 class="mt-5 text-sm font-semibold text-slate-200">Via pip</h3>
            <pre class="mt-2 overflow-x-auto rounded-md bg-slate-900/80 p-3 text-xs font-mono text-slate-100">pip install llm-supercli</pre>

            <h3 class="mt-5 text-sm font-semibold text-slate-200">Start the CLI</h3>
            <pre class="mt-2 overflow-x-auto rounded-md bg-slate-900/80 p-3 text-xs font-mono text-slate-100">llm
# Or use the full command
llm-supercli</pre>

            <h3 class="mt-5 text-sm font-semibold text-slate-200">Set up authentication (for free providers)</h3>
            <pre class="mt-2 overflow-x-auto rounded-md bg-slate-900/80 p-3 text-xs font-mono text-slate-100"># Qwen (free - 2K requests/day)
npm install -g @qwen-code/qwen-code
qwen  # Follow OAuth flow

# Gemini (free)
npm install -g @anthropic-ai/gemini-cli
gemini  # Follow OAuth flow</pre>
          </div>

          <div class="space-y-4 rounded-lg border border-slate-800 bg-slate-900/50 p-4 text-sm text-slate-300">
            <p class="font-medium text-slate-100">API Key Providers</p>
            <p class="text-sm text-slate-400">
              Set environment variables or use the /key command for API key providers.
            </p>
            <pre class="overflow-x-auto rounded-md bg-slate-950/70 p-3 text-xs font-mono text-slate-100">export GROQ_API_KEY=your_key
export OPENROUTER_API_KEY=your_key
export TOGETHER_API_KEY=your_key
export HF_API_KEY=your_key

# Or set via CLI
/key groq your_api_key</pre>
            <a
              href="https://github.com/llm-supercli/llm-supercli"
              target="_blank"
              rel="noreferrer"
              class="inline-flex items-center justify-center rounded-md border border-sky-500/70 bg-slate-950/40 px-4 py-2 text-xs font-semibold text-sky-300 hover:border-sky-400 hover:bg-slate-950/80"
            >
              View full documentation
            </a>
          </div>
        </div>
      </section>

      <!-- Commands -->
      <section id="commands" class="mt-16 scroll-mt-24">
        <h2 class="text-xl font-semibold text-slate-50 sm:text-2xl">Commands</h2>
        <p class="mt-2 max-w-2xl text-sm text-slate-400">
          Built-in slash commands for managing sessions, models, and settings.
        </p>

        <div class="mt-6 grid gap-6 md:grid-cols-2">
          <div class="rounded-lg border border-slate-800 bg-slate-900/60 p-5">
            <p class="text-sm font-semibold text-slate-100 mb-4">Available Commands</p>
            <div class="grid grid-cols-2 gap-2 text-xs">
              <div class="flex justify-between"><span class="text-sky-300">/help</span><span class="text-slate-400">Show help</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/model</span><span class="text-slate-400">Switch model</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/settings</span><span class="text-slate-400">Edit settings</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/sessions</span><span class="text-slate-400">Manage sessions</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/new</span><span class="text-slate-400">New chat</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/clear</span><span class="text-slate-400">Clear screen</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/status</span><span class="text-slate-400">Show status</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/cost</span><span class="text-slate-400">Token usage</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/key</span><span class="text-slate-400">Set API key</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/mcp</span><span class="text-slate-400">MCP servers</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/compress</span><span class="text-slate-400">Compress context</span></div>
              <div class="flex justify-between"><span class="text-sky-300">/rewind</span><span class="text-slate-400">Rewind message</span></div>
            </div>
          </div>

          <div class="rounded-lg border border-slate-800 bg-slate-900/60 p-5 text-sm text-slate-300">
            <p class="font-medium text-slate-100">Special Syntax</p>
            <p class="mt-2 text-sm text-slate-400">
              Use special prefixes to include files or run shell commands.
            </p>
            <pre class="mt-3 overflow-x-auto rounded-md bg-slate-950/70 p-3 text-xs font-mono text-slate-100"># Execute shell command
!ls -la
!git status

# Include file contents in prompt
@path/to/file.py
Tell me about @src/main.py

# Multiple files
Explain @file1.py and @file2.py</pre>
          </div>
        </div>
      </section>

      <!-- Built-in Tools -->
      <section id="tools" class="mt-16 scroll-mt-24">
        <h2 class="text-xl font-semibold text-slate-50 sm:text-2xl">Built-in Tools</h2>
        <p class="mt-2 max-w-2xl text-sm text-slate-400">
          The LLM can use these tools during conversations to interact with your system.
        </p>

        <div class="mt-6 grid gap-4 md:grid-cols-3">
          <div class="rounded-lg border border-slate-800 bg-slate-900/50 p-4">
            <code class="text-xs text-sky-300">list_directory(path)</code>
            <p class="mt-1 text-xs text-slate-400">List files and folders</p>
          </div>
          <div class="rounded-lg border border-slate-800 bg-slate-900/50 p-4">
            <code class="text-xs text-sky-300">read_file(path)</code>
            <p class="mt-1 text-xs text-slate-400">Read file contents</p>
          </div>
          <div class="rounded-lg border border-slate-800 bg-slate-900/50 p-4">
            <code class="text-xs text-sky-300">write_file(path, content)</code>
            <p class="mt-1 text-xs text-slate-400">Create or write a file</p>
          </div>
          <div class="rounded-lg border border-slate-800 bg-slate-900/50 p-4">
            <code class="text-xs text-sky-300">create_directory(path)</code>
            <p class="mt-1 text-xs text-slate-400">Create a folder</p>
          </div>
          <div class="rounded-lg border border-slate-800 bg-slate-900/50 p-4">
            <code class="text-xs text-sky-300">run_command(command)</code>
            <p class="mt-1 text-xs text-slate-400">Run shell command</p>
          </div>
          <div class="rounded-lg border border-slate-800 bg-slate-900/50 p-4">
            <code class="text-xs text-sky-300">get_current_directory()</code>
            <p class="mt-1 text-xs text-slate-400">Get current working directory</p>
          </div>
        </div>
      </section>
    </main>

    <footer class="border-t border-slate-800 bg-slate-950/90">
      <div class="mx-auto flex max-w-6xl flex-col gap-3 px-4 py-6 text-xs text-slate-400 sm:flex-row sm:items-center sm:justify-between sm:text-sm">
        <p>
          &copy; 2025 LLM SuperCLI v1.0.18 · Python 3.10+ · MIT License
        </p>
        <div class="flex flex-wrap items-center gap-4">
          <a
            href="https://github.com/llm-supercli/llm-supercli"
            target="_blank"
            rel="noreferrer"
            class="inline-flex items-center gap-1 text-sky-300 hover:text-sky-200"
          >
            <span class="h-1.5 w-1.5 rounded-full bg-sky-400"></span>
            <span>View on GitHub</span>
          </a>
          <a
            href="https://www.npmjs.com/package/llm-supercli"
            target="_blank"
            rel="noreferrer"
            class="inline-flex items-center gap-1 text-sky-300 hover:text-sky-200"
          >
            <span class="h-1.5 w-1.5 rounded-full bg-sky-400"></span>
            <span>npm</span>
          </a>
          <p class="text-slate-500">Made with love for the CLI community</p>
        </div>
      </div>
    </footer>
  </div>
</body>
</html>
